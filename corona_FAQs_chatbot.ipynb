{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "corona FAQs chatbot.ipynb",
      "provenance": [],
      "mount_file_id": "15X7x1MXx81VZeRaxqc2FFK5WNTYgWjLg",
      "authorship_tag": "ABX9TyOnHGQvoAHLrbdUuoXNxVl3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ech-Charay/Corona-FAQs-chatbot/blob/master/corona_FAQs_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQoUVc-Y7rj_",
        "colab_type": "text"
      },
      "source": [
        "# **Installing prerequisites:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7lagrE7HUWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bda7f052-567a-4b48-bf41-291651059dbe"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.6.20)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd8NdSES7MKK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fb26480b-3492-42cf-9e81-2c76da02035e"
      },
      "source": [
        "!wget \"https://download.pytorch.org/models/tutorials/4000_checkpoint.tar\" "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-13 23:42:21--  https://download.pytorch.org/models/tutorials/4000_checkpoint.tar\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.35.34.50, 13.35.34.52, 13.35.34.129, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.35.34.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257811088 (246M) [application/x-tar]\n",
            "Saving to: ‘4000_checkpoint.tar.2’\n",
            "\n",
            "4000_checkpoint.tar 100%[===================>] 245.87M  26.0MB/s    in 11s     \n",
            "\n",
            "2020-07-13 23:42:33 (23.1 MB/s) - ‘4000_checkpoint.tar.2’ saved [257811088/257811088]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZTWf7mDvVPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4cf4ccc8-01d8-4149-c77a-04d59df9f31a"
      },
      "source": [
        "!pip3 install SpeechRecognition"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.6/dist-packages (3.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W_LIHsWvVMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "98f5cb98-2357-4b78-9ed7-128981f83c62"
      },
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1).\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.5).\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.6/dist-packages (0.2.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsT20b6wvVJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "38137331-3a5d-4b76-8b3d-db42417a9ea6"
      },
      "source": [
        "!pip install ffmpeg-python"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cImHcSC6vVGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8c0e9c5b-fffe-456f-c31d-7d2a49b63e68"
      },
      "source": [
        "!pip install gtts"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gtts in /usr/local/lib/python3.6/dist-packages (2.1.1)\n",
            "Requirement already satisfied: gtts-token>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from gtts) (1.1.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gtts) (4.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gtts) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from gtts) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gtts) (1.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6zyxn6XD-0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p /content/records/in /content/records/out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cio_30Kv6GMP",
        "colab_type": "text"
      },
      "source": [
        "# **First part of the chatbot: cosine-similarity based Retrieval chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq1J0M9h61g7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess raw text Excel file into CSV using spaCy to tokenize sentences\n",
        "\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import spacy\n",
        "\n",
        "\n",
        "def preprocess(entry):\n",
        "    '''\n",
        "    Normalize string argument entry, remove new line characters,\n",
        "    add space after '?' chars, and return entry with trailing space.\n",
        "    '''\n",
        "    entry = entry.replace('\\n', ' ')\n",
        "    entry = unicodedata.normalize(\"NFKD\", entry)\n",
        "    entry = entry.replace('?', '? ')\n",
        "    return entry + ' '\n",
        "\n",
        "\n",
        "def sentence_tokenize(entry):\n",
        "    '''\n",
        "    Tokenize string argument entry into sentences using spaCy,\n",
        "    then join sentences with double new lines and return as string.\n",
        "    '''\n",
        "    doc = nlp(entry)\n",
        "    sentences = list(doc.sents)\n",
        "    sentences = '\\n\\n'.join([(s.text) for s in sentences])\n",
        "    return sentences\n",
        "\n",
        "    \n",
        "def paragraph_tokenize(entry):\n",
        "    '''\n",
        "    Tokenize string argument entry into paragraphs,\n",
        "    then join sentences with double new lines and return as string.\n",
        "    '''\n",
        "\n",
        "    bloc = []\n",
        "    paragraphs = []\n",
        "    for s in entry.split('\\n'):\n",
        "      if len(s) == 0:\n",
        "        continue\n",
        "      elif (s[0] == '-' or s[0] == '*' or s[0] == '+' or (s[0] >= '0' and s[0] <= '9')) :\n",
        "        bloc.append(s)\n",
        "      elif len(bloc) != 0:\n",
        "        paragraphs.append('\\n'.join(bloc))\n",
        "        paragraphs.append(s)\n",
        "        bloc = []\n",
        "      else :\n",
        "        paragraphs.append(s)\n",
        "    if len(bloc) != 0:\n",
        "      paragraphs.append('\\n'.join(bloc))\n",
        "    return '\\n\\n'.join(paragraphs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOR4SGsR7Qyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b22baca9-5e5d-45aa-8470-804d371c8b15"
      },
      "source": [
        "spacy_model = 'en_core_web_sm'\n",
        "print('Loading spaCy model', spacy_model, '...')\n",
        "nlp = spacy.load(spacy_model)\n",
        "print('-Done.')\n",
        "faq = pd.read_excel(\"/content/drive/My Drive/MyFirstChatBot/data/Q&A_COVID-19.xlsx\")\n",
        "#faq = raw.drop(labels=('Active'), axis=1).dropna()\n",
        "#faq.question = faq.question.apply(preprocess)\n",
        "#faq.question = faq.question.apply(sentence_tokenize)\n",
        "#faq.answer = faq.answer.apply(preprocess)\n",
        "#faq.answer = faq.answer.apply(sentence_tokenize)\n",
        "faq.answer = faq.answer.apply(paragraph_tokenize)\n",
        "faq.to_csv('/content/drive/My Drive/MyFirstChatBot/data/faq-text-preprocessed.csv', index=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading spaCy model en_core_web_sm ...\n",
            "-Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oga9Yj9EMIh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "449d2fc6-28a2-44bd-b7b6-93c1ed0778e0"
      },
      "source": [
        "import string\n",
        "from sklearn.feature_extraction import stop_words\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "class Processing:\n",
        "  def __init__(self):\n",
        "    print(\"init processing\")\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "  def lem(self, words):\n",
        "      \"\"\"Returns list of lemmas from argument list of words.\"\"\"\n",
        "      wordnet_lemmatizer = WordNetLemmatizer()\n",
        "      lem_sentence = []\n",
        "      for word in words:\n",
        "          lem_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "      return lem_sentence\n",
        "\n",
        "\n",
        "  def text_process(self, mess, lemmas=True):\n",
        "      \"\"\"\n",
        "      Returns list of tokenized lemmas in argument string mess, with stopwords,\n",
        "      punctuation removed.\n",
        "      \"\"\"\n",
        "      clean = [char if char not in string.punctuation else ' ' for char in mess]\n",
        "      clean = ''.join(clean)\n",
        "      clean = [word.lower() for word in clean.split() if word.lower()\n",
        "              not in stop_words.ENGLISH_STOP_WORDS]\n",
        "      \n",
        "      if lemmas:\n",
        "          clean = self.lem(clean)\n",
        "          \n",
        "      return clean"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZypKa_M8hU-",
        "colab_type": "text"
      },
      "source": [
        "# **Second part of the chatbot: Generative smart chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxDIbH3ytWWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cpu\") # TODO mn l2fdal khlliha cpu bax maykerjox lik machakil mn jenb khossosan trained model mtraine 3la cpu\n",
        "\n",
        "\n",
        "MAX_LENGTH = 10  # Maximum sentence length\n",
        "\n",
        "# Default word tokens\n",
        "PAD_token = 0  # Used for padding short sentences\n",
        "SOS_token = 1  # Start-of-sentence token\n",
        "EOS_token = 2  # End-of-sentence token"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwTKCHccvAeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count SOS, EOS, PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Remove words below a certain count threshold\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "        keep_words = []\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "        # Reinitialize dictionaries\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3 # Count default tokens\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)\n",
        "\n",
        "\n",
        "# Lowercase and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "# Takes string sentence, returns sentence of word indexes\n",
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGR6B1cbvAbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        #   because our input size is a word embedding with number of features == hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # type: (Tensor, Tensor, Optional[Tensor]) -> Tuple[Tensor, Tensor]\n",
        "        # Convert word indexes to embeddings\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        # Forward pass through GRU\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # Unpack padding\n",
        "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        # Sum bidirectional GRU outputs\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        # Return output and final hidden state\n",
        "        return outputs, hidden"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR1lHsJR5SJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Luong attention layer\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfwv3bnn5WK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step (word) at a time\n",
        "        # Get embedding of current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return output and final hidden state\n",
        "        return output, hidden"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_uXy1yy9whg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, decoder_n_layers):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self._device = device\n",
        "        self._SOS_token = SOS_token\n",
        "        self._decoder_n_layers = decoder_n_layers\n",
        "\n",
        "    __constants__ = ['_device', '_SOS_token', '_decoder_n_layers']\n",
        "\n",
        "    def forward(self, input_seq : torch.Tensor, input_length : torch.Tensor, max_length : int):\n",
        "        # Forward input through encoder model\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:self._decoder_n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "        decoder_input = torch.ones(1, 1, device=self._device, dtype=torch.long) * self._SOS_token\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=self._device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=self._device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ZrjFpO899m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0fd58229-8d86-45c8-b359-c6dabba57eb7"
      },
      "source": [
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "corpus_name = \"cornell movie-dialogs corpus\"\n",
        "\n",
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "# If you're loading your own model\n",
        "# Set checkpoint to load from\n",
        "checkpoint_iter = 4000\n",
        "# loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                             '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                             '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "# If you're loading the hosted model\n",
        "loadFilename = '/content/4000_checkpoint.tar'\n",
        "\n",
        "# Load model\n",
        "# Force CPU device options (to match tensors in this tutorial)\n",
        "checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "encoder_sd = checkpoint['en']\n",
        "decoder_sd = checkpoint['de']\n",
        "encoder_optimizer_sd = checkpoint['en_opt']\n",
        "decoder_optimizer_sd = checkpoint['de_opt']\n",
        "embedding_sd = checkpoint['embedding']\n",
        "voc = Voc(corpus_name)\n",
        "voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "# Load trained model params\n",
        "encoder.load_state_dict(encoder_sd)\n",
        "decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "# Set dropout layers to eval mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "print('Models built and ready to go!')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OnoByFLO7Uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### Format input sentence as a batch\n",
        "    # words -> indexes\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "    # Create lengths tensor\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # Transpose dimensions of batch to match models' expectations\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    # Use appropriate device\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "    # Decode sentence with searcher\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # indexes -> words\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words\n",
        "\n",
        "\n",
        "\n",
        "from gtts import gTTS #Import Google Text to Speech\n",
        "from IPython.display import Audio  \n",
        "\n",
        "\n",
        "\n",
        "# Evaluate inputs from user input (stdin)\n",
        "def evaluateInput(searcher, voc,input_sentence):\n",
        "    #input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence\n",
        "            #input_sentence = input('> ')\n",
        "            # Check if it is quit case\n",
        "            #if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "            # Normalize sentence\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            # Evaluate sentence\n",
        "            output_words = evaluate(searcher, voc, input_sentence)\n",
        "            # Format and print response sentence\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            engine = gTTS(''.join(output_words))  \n",
        "            engine.save('a1.wav') \n",
        "            Audio('a1.wav', autoplay=True)  \n",
        "            print('Bot:', ' '.join(output_words))\n",
        "        except KeyError:\n",
        "            print(\"Error: Encountered unknown word.\")\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate inputs from user input (stdin)\n",
        "def evaluateInput2(searcher, voc):\n",
        "  input_sentence = ''\n",
        "  try:\n",
        "    # Get input sentence\n",
        "    input_sentence = input('> ')\n",
        "    # Check if it is quit case\n",
        "    # Normalize sentence\n",
        "    input_sentence = normalizeString(input_sentence)\n",
        "    # Evaluate sentence\n",
        "    output_words = evaluate(searcher, voc, input_sentence)\n",
        "    # Format and print response sentence\n",
        "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "    print('Bot:', ' '.join(output_words))\n",
        "    bot_answer=' '.join(output_words)\n",
        "    engine = gTTS(''+bot_answer)  \n",
        "    engine.save('a1.wav') \n",
        "  except KeyError:\n",
        "    print(\"Error: Encountered unknown word.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Normalize input sentence and call evaluate()\n",
        "def evaluateExample(sentence, searcher, voc):\n",
        "    print(\"> \" + sentence)\n",
        "    # Normalize sentence\n",
        "    input_sentence = normalizeString(sentence)\n",
        "    # Evaluate sentence\n",
        "    output_words = evaluate(searcher, voc, input_sentence)\n",
        "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "    print('Bot:', ' '.join(output_words))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erEtYvKr6TdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize search module\n",
        "searcher = GreedySearchDecoder(encoder, decoder,decoder_n_layers)\n",
        "#evaluateInput2(searcher,voc) TODO t9der tkhdem bhad l fonction fiha while ms kadir dal lprblm li dwit lik 3lih"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMdICs1t-m1x",
        "colab_type": "text"
      },
      "source": [
        "# **Bot Server:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y4kCqcJMJ5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "from datetime import datetime\n",
        "import random \n",
        "\n",
        "#import processing\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from flask import jsonify, request\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "\n",
        "class BotServer:\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"\n",
        "        Initialize corpus, bag-of-words, and TFIDF from CSV file at argument\n",
        "        file_path.\n",
        "        \"\"\"\n",
        "        processing = Processing()\n",
        "        # Read in FAQ data\n",
        "        self.faq = pd.read_csv(file_path, keep_default_na=False)\n",
        "        self.corpus = self.faq.question + ' ' + self.faq.answer\n",
        "\n",
        "        # Create BOW tranformer based on faq.question + faq.answer\n",
        "        self.bow_transformer = CountVectorizer(analyzer=processing.text_process).fit(self.faq.question)\n",
        "        # Tranform faq.question itself into BOW\n",
        "        self.corpus_bow = self.bow_transformer.transform(self.faq.question)\n",
        "\n",
        "        # Create TFIDF transformer based on faq.question's BOW\n",
        "        self.tfidf_transformer = TfidfTransformer().fit(self.corpus_bow)\n",
        "        # Transform faq.question's BOW into TFIDF\n",
        "        self.corpus_tfidf = self.tfidf_transformer.transform(self.corpus_bow)\n",
        "\n",
        "        # Set upload folder and output records folder\n",
        "        self.UPLOAD_FOLDER = '/content/records/in'\n",
        "        self.REC_RES_FOLDER = '/content/records/out'\n",
        "\n",
        "        # Set allowed extensions\n",
        "        self.ALLOWED_EXTENSIONS = {'wav'}\n",
        "\n",
        "    def tfidf_similarity(self, query):\n",
        "        \"\"\"\n",
        "        Returns (index, similarity value) of string argument query's most similar\n",
        "        match in FAQ, determined by cosine similarity.\n",
        "        \"\"\"\n",
        "        # Transform test question into BOW using BOW transformer\n",
        "        query_bow = self.bow_transformer.transform([query])\n",
        "        # Transform test question's BOW into TFIDF\n",
        "        query_tfidf = self.tfidf_transformer.transform(query_bow)\n",
        "\n",
        "        # Calculate cosine similarity and return maximum value with accompanying index\n",
        "        similarities = np.transpose(cosine_similarity(query_tfidf, self.corpus_tfidf))\n",
        "        max_similarity = similarities.max()\n",
        "        max_index = np.argmax(similarities)\n",
        "\n",
        "        return max_index, max_similarity\n",
        "\n",
        "    def match_query(self, query):\n",
        "        \"\"\"\n",
        "        Prints most similar match in FAQ to user query.\n",
        "        \"\"\"\n",
        "        index, similarity = self.tfidf_similarity(query)\n",
        "\n",
        "        if similarity > 0.5 :\n",
        "          response = self.faq.answer.iloc[index]\n",
        "          print(similarity)\n",
        "        else :\n",
        "          query = normalizeString(query)\n",
        "          output_words = evaluate(searcher, voc, query)\n",
        "          output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "          response = ' '.join(output_words)\n",
        "       \n",
        "        return response\n",
        "\n",
        "    def allowed_file(self, filename):\n",
        "      return '.' in filename and filename.rsplit('.', 1)[1].lower() in self.ALLOWED_EXTENSIONS\n",
        "\n",
        "    def bot_dialog(self, request):\n",
        "        \"\"\"\n",
        "        Given the argument POST request, parse it according to json or form data,\n",
        "        and return a json response or html template based on sklearn matching\n",
        "        within the FAQ.\n",
        "        \"\"\"\n",
        "        \n",
        "        print('****************')\n",
        "        # Handle webhook request\n",
        "        #.get_json(force=True)\n",
        "        req = request.form\n",
        "        msg_type = req.get('type')\n",
        "        if msg_type == \"Text\":\n",
        "          message = req.get('message')\n",
        "          response_text = self.match_query(message)\n",
        "          # Return json file as webhook response \n",
        "          messages = [\n",
        "                      {\n",
        "                          \"type\": \"Text\",\n",
        "                          \"message\": msg,\n",
        "                          \"fromBot\": True\n",
        "                      }\n",
        "                      for msg in response_text.split(\"\\n\\n\")\n",
        "                      ]\n",
        "        elif msg_type == \"Audio\":\n",
        "          record = request.files['record']\n",
        "          if record and self.allowed_file(record.filename):\n",
        "            filename = secure_filename(record.filename)\n",
        "            record.save(os.path.join(self.UPLOAD_FOLDER, filename))\n",
        "          list_records = []\n",
        "          try:\n",
        "            r = spechrec.Recognizer()\n",
        "            with spechrec.AudioFile(os.path.join(self.UPLOAD_FOLDER, filename)) as source:\n",
        "              # listen for the data (load audio to memory)\n",
        "              audio_data = r.record(source)\n",
        "              # recognize (convert from speech to text)\n",
        "              input_sentence = r.recognize_google(audio_data)\n",
        "            response_text = self.match_query(searcher, voc, input_sentence)\n",
        "            for msg in response_text.split(\"\\n\\n\"):\n",
        "              now = datetime.now()\n",
        "              respfilename = now.strftime(\"%d-%m-%Y-%H:%M:%S\") + \".wav\"\n",
        "              engine = gTTS('' + response_text)\n",
        "              engine.save(os.path.join(self.REC_RES_FOLDER, respfilename))\n",
        "              list_records.append(respfilename)\n",
        "          except:\n",
        "            erreur = random.choice([\"Sorry, i did not understand you ,Please change the way you say it\",\n",
        "                          \"please be a little simple in your discussion i m not a human\",\n",
        "                          \"Sorry, get in mind  that you are talking only with a computer \"])\n",
        "            print(\"\"+erreur)\n",
        "            now = datetime.now()\n",
        "            respfilename = now.strftime(\"%d-%m-%Y-%H:%M:%S\") + \".wav\"\n",
        "            engine = gTTS(''+erreur)\n",
        "            engine.save(os.path.join(self.REC_RES_FOLDER, respfilename))\n",
        "            list_records.append(respfilename)\n",
        "          duration = round(librosa.get_duration(filename=os.path.join(self.REC_RES_FOLDER, respfilename)))\n",
        "          # Return json file as webhook response \n",
        "          messages = [\n",
        "                      {\n",
        "                          \"type\": \"Audio\",\n",
        "                          \"path\": \"http://b1ec39a3df14.ngrok.io/records/\"+respfilename,\n",
        "                          \"isLocal\": False,\n",
        "                          \"duration\": duration,\n",
        "                          \"fromBot\": True\n",
        "                      }\n",
        "                      for filename in list_records\n",
        "                      ]\n",
        "        return jsonify({\"messages\": messages})"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSuYl9B8SO_",
        "colab_type": "text"
      },
      "source": [
        "# **Main APP:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O2pMPHlNqRo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a979f988-c716-47b4-80ea-a5c4dd8c7cc4"
      },
      "source": [
        "bot = BotServer('/content/drive/My Drive/MyFirstChatBot/data/faq-text-preprocessed.csv')\n",
        "while(1):\n",
        "  try:\n",
        "    # Get input sentence\n",
        "    input_sentence = input('> ')\n",
        "    # Check if it is quit case\n",
        "    if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "    # Evaluate sentence\n",
        "    output_words = bot.match_query(input_sentence)\n",
        "    print('Bot:', ''.join(output_words))\n",
        "  except KeyError:\n",
        "    print(\"Error: Encountered unknown word.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init processing\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "> q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrPQ_igQBYj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "3cbfdd66-973a-460f-8e24-8d9ca5f0a2a3"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, jsonify, json, send_from_directory\n",
        "\n",
        "app = Flask(__name__, static_url_path='')\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    \"\"\"\n",
        "    This route at the home page renders the index.html template with blank\n",
        "    variables.\n",
        "    \"\"\"\n",
        "    \n",
        "    return jsonify(\n",
        "        messages = [\n",
        "            {\n",
        "                \"message\": \"Hello!\",\n",
        "                \"fromBot\": True\n",
        "            },\n",
        "            {\n",
        "                \"message\": \"How are you?\",\n",
        "                \"fromBot\": True\n",
        "            },\n",
        "            {\n",
        "                \"message\": \"You can ask me what ever you want about coronavirus.\",\n",
        "                \"fromBot\": True\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "@app.route('/dialog', methods=['POST'])\n",
        "def dialog():\n",
        "    \"\"\"\n",
        "    This route uses the POST method to take user request and return the result\n",
        "    of passing it to the BotServer similarity matching function.\n",
        "    \"\"\"\n",
        "    return bot.bot_dialog(request)\n",
        "\n",
        "@app.route('/records/<path:filename>', methods=['GET', 'POST'])\n",
        "def download(filename):\n",
        "    return send_from_directory(directory='/content/records/out', filename=filename)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \"\"\"\n",
        "    Default Python entrypoint creates Botserver object and runs Flask app.\n",
        "    \"\"\"\n",
        "    bot = BotServer('/content/drive/My Drive/MyFirstChatBot/data/faq-text-preprocessed.csv')\n",
        "\n",
        "    app.run()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init processing\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://e2bf0db4d9dd.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "****************\n",
            "Sorry, get in mind  that you are talking only with a computer \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [13/Jul/2020 23:57:40] \"\u001b[37mPOST /dialog HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [13/Jul/2020 23:58:40] \"\u001b[37mGET /records/13-07-2020-23:57:39.wav HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}